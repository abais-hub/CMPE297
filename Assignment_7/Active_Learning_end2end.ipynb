{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "linking",
      "language": "python",
      "name": "linking"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Active_Learning_end2end.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E0VlV1nXyf4"
      },
      "source": [
        "# CMPE 297 HW 7 - Active Learning end2end\n",
        "## Abhishek Bais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je2b00hlXyf_"
      },
      "source": [
        "#1.0 Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkkc50YJXygB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35166b7b-c749-498d-e3cb-5b724aa04376"
      },
      "source": [
        "# Check if we're running locally, or in Google Colab.\n",
        "try:\n",
        "    import google.colab\n",
        "    COLAB = True\n",
        "except ModuleNotFoundError:\n",
        "    COLAB = False\n",
        "    \n",
        "# If we're running in Colab, download the tutorial functions file \n",
        "# to the Colab session local directory, and install required libraries.\n",
        "if COLAB:\n",
        "    import requests\n",
        "    \n",
        "    tutorial_functions_url = \"https://raw.githubusercontent.com/rachhouse/intro-to-data-linking/main/tutorial_notebooks/linking_tutorial_functions.py\"\n",
        "    r = requests.get(tutorial_functions_url)\n",
        "    \n",
        "    with open(\"linking_tutorial_functions.py\", \"w\") as fh:\n",
        "        fh.write(r.text)\n",
        "    \n",
        "    !pip install -q altair dedupe dedupe-variable-name jellyfish recordlinkage "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 90 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 764 kB 45.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 137 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 944 kB 37.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 103 kB 39.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 531 kB 27.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 14.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 155 kB 71.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 71 kB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 253 kB 41.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 251 kB 43.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 787 kB 59.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 203 kB 68.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 888 kB 58.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 743 kB 68.6 MB/s \n",
            "\u001b[?25h  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0T2JmjJc3HI"
      },
      "source": [
        "# 2.0 Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN2rEpZcd_P6",
        "outputId": "54aa846e-697e-4950-f225-1ea245e0b608"
      },
      "source": [
        "!pip install dedupe"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dedupe in /usr/local/lib/python3.7/dist-packages (2.0.8)\n",
            "Requirement already satisfied: zope.index in /usr/local/lib/python3.7/dist-packages (from dedupe) (5.1.0)\n",
            "Requirement already satisfied: BTrees>=4.1.4 in /usr/local/lib/python3.7/dist-packages (from dedupe) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from dedupe) (1.19.5)\n",
            "Requirement already satisfied: highered>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from dedupe) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dedupe) (3.10.0.2)\n",
            "Requirement already satisfied: simplecosine>=1.2 in /usr/local/lib/python3.7/dist-packages (from dedupe) (1.2)\n",
            "Requirement already satisfied: dedupe-hcluster in /usr/local/lib/python3.7/dist-packages (from dedupe) (0.3.8)\n",
            "Requirement already satisfied: dedupe-variable-datetime in /usr/local/lib/python3.7/dist-packages (from dedupe) (0.1.5)\n",
            "Requirement already satisfied: fastcluster in /usr/local/lib/python3.7/dist-packages (from dedupe) (1.2.4)\n",
            "Requirement already satisfied: rlr>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from dedupe) (2.4.5)\n",
            "Requirement already satisfied: haversine>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from dedupe) (2.5.1)\n",
            "Requirement already satisfied: categorical-distance>=1.9 in /usr/local/lib/python3.7/dist-packages (from dedupe) (1.9)\n",
            "Requirement already satisfied: doublemetaphone in /usr/local/lib/python3.7/dist-packages (from dedupe) (0.1)\n",
            "Requirement already satisfied: Levenshtein-search in /usr/local/lib/python3.7/dist-packages (from dedupe) (1.4.5)\n",
            "Requirement already satisfied: affinegap>=1.3 in /usr/local/lib/python3.7/dist-packages (from dedupe) (1.11)\n",
            "Requirement already satisfied: zope.interface>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from BTrees>=4.1.4->dedupe) (5.4.0)\n",
            "Requirement already satisfied: persistent>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from BTrees>=4.1.4->dedupe) (4.7.0)\n",
            "Requirement already satisfied: pyhacrf-datamade>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from highered>=0.2.0->dedupe) (0.2.5)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from persistent>=4.1.0->BTrees>=4.1.4->dedupe) (1.15.0)\n",
            "Requirement already satisfied: PyLBFGS>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from pyhacrf-datamade>=0.2.0->highered>=0.2.0->dedupe) (0.2.0.13)\n",
            "Requirement already satisfied: future>=0.14 in /usr/local/lib/python3.7/dist-packages (from rlr>=2.4.3->dedupe) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=5.0.0->BTrees>=4.1.4->dedupe) (57.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->persistent>=4.1.0->BTrees>=4.1.4->dedupe) (2.21)\n",
            "Requirement already satisfied: datetime-distance in /usr/local/lib/python3.7/dist-packages (from dedupe-variable-datetime->dedupe) (0.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from datetime-distance->dedupe-variable-datetime->dedupe) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.0->datetime-distance->dedupe-variable-datetime->dedupe) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfkXFVEdXygC"
      },
      "source": [
        "import datetime\n",
        "import itertools\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "import dedupe\n",
        "import pandas as pd\n",
        "\n",
        "import linking_tutorial_functions as tutorial"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfecmhtrXygD"
      },
      "source": [
        "#3.0 Define Working env,filepaths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMmFUgypXygD"
      },
      "source": [
        "For convenience, we'll define a `pathlib.Path` to reference our current working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZvS8WguXygE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9363ff4a-7355-4a21-f107-cc8778f54d99"
      },
      "source": [
        "WORKING_DIR = pathlib.Path(os.path.abspath(''))\n",
        "WORKING_DIR"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-8VaYI2XygF"
      },
      "source": [
        "#4.0 Load Training Dataset and Ground Truth Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr6rZQ2lXygF"
      },
      "source": [
        "df_A, df_B, df_ground_truth = tutorial.load_febrl_training_data(COLAB)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8W71JopXygF"
      },
      "source": [
        "Let's take a quick look at our training dataset to refresh on the columns, formats, and data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OECkk06LXygG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "66e44e7d-2426-412c-d304-eea90ffac0eb"
      },
      "source": [
        "df_A.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_name</th>\n",
              "      <th>surname</th>\n",
              "      <th>street_number</th>\n",
              "      <th>address_1</th>\n",
              "      <th>address_2</th>\n",
              "      <th>suburb</th>\n",
              "      <th>postcode</th>\n",
              "      <th>state</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>age</th>\n",
              "      <th>phone_number</th>\n",
              "      <th>soc_sec_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>person_id_A</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fbc4143d-15f9-4f27-b5f0-dedbadce6616</th>\n",
              "      <td>matilda</td>\n",
              "      <td>struck</td>\n",
              "      <td>8</td>\n",
              "      <td>ballard place</td>\n",
              "      <td></td>\n",
              "      <td>west perth</td>\n",
              "      <td>2470</td>\n",
              "      <td>qld</td>\n",
              "      <td>19611002</td>\n",
              "      <td>32</td>\n",
              "      <td>03 05903135</td>\n",
              "      <td>8276847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48a56cad-7ba6-45e1-97cd-517ba65bdab5</th>\n",
              "      <td>lachlan</td>\n",
              "      <td>eglinton</td>\n",
              "      <td>36</td>\n",
              "      <td>kambalda crescent</td>\n",
              "      <td>villa 427</td>\n",
              "      <td>auburn</td>\n",
              "      <td>5109</td>\n",
              "      <td></td>\n",
              "      <td>19260108</td>\n",
              "      <td>27</td>\n",
              "      <td></td>\n",
              "      <td>9937958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b1792d21-e4be-4b86-8dea-454ffa5194c5</th>\n",
              "      <td>mikayla</td>\n",
              "      <td>asher</td>\n",
              "      <td>588</td>\n",
              "      <td>britten-jones drive</td>\n",
              "      <td></td>\n",
              "      <td>miami</td>\n",
              "      <td>4218</td>\n",
              "      <td>nsw</td>\n",
              "      <td>19251102</td>\n",
              "      <td>32</td>\n",
              "      <td>03 33770501</td>\n",
              "      <td>7017310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96653d73-bebc-4459-94f3-c3f0a8c514d4</th>\n",
              "      <td>grace</td>\n",
              "      <td>bristow</td>\n",
              "      <td>7</td>\n",
              "      <td></td>\n",
              "      <td>wandella park snowy</td>\n",
              "      <td>cardiff</td>\n",
              "      <td>6163</td>\n",
              "      <td>nsw</td>\n",
              "      <td>19400120</td>\n",
              "      <td></td>\n",
              "      <td>07 37864073</td>\n",
              "      <td>3535974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41f038b8-77c0-45a5-9e1f-e62b8637ffd1</th>\n",
              "      <td>wilson</td>\n",
              "      <td>bishop</td>\n",
              "      <td>11</td>\n",
              "      <td>chisholm street</td>\n",
              "      <td></td>\n",
              "      <td>bronte</td>\n",
              "      <td>2490</td>\n",
              "      <td>nsw</td>\n",
              "      <td>19210305</td>\n",
              "      <td>27</td>\n",
              "      <td>04 15209769</td>\n",
              "      <td>5573522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     first_name  ... soc_sec_id\n",
              "person_id_A                                      ...           \n",
              "fbc4143d-15f9-4f27-b5f0-dedbadce6616    matilda  ...    8276847\n",
              "48a56cad-7ba6-45e1-97cd-517ba65bdab5    lachlan  ...    9937958\n",
              "b1792d21-e4be-4b86-8dea-454ffa5194c5    mikayla  ...    7017310\n",
              "96653d73-bebc-4459-94f3-c3f0a8c514d4      grace  ...    3535974\n",
              "41f038b8-77c0-45a5-9e1f-e62b8637ffd1     wilson  ...    5573522\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3csiZcLXygG"
      },
      "source": [
        "# 5.0 Perform Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FKHuPPgXygG"
      },
      "source": [
        "We'll do minimal data augmentation before feeding our training data to `dedupe`; we just want to format the date of birth data as `mm/dd/yy`, and ensure all columns are in string format and stripped of trailing/leading whitespace. Additionally, `dedupe` requires input data to be in dictionaries, using the record id as the key and the record metadata as the value. So, we'll convert our dataframes to this format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnEU0C3-XygG"
      },
      "source": [
        "def format_dob(dob: str) -> Optional[str]:\n",
        "    \"\"\" Transform date of birth format from YYYYMMDD to mm/dd/yy.\n",
        "        If DOB cannot be transformed, return None.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if re.match(r\"\\d{8}\", dob):\n",
        "            return (datetime.datetime.strptime(dob, \"%Y%m%d\")).strftime(\"%m/%d/%y\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "def strip_and_null(x: Any) -> Optional[str]:\n",
        "    \"\"\" Stringify incoming variable, remove trailing/leading whitespace\n",
        "        and return resulting string. Return None if resulting string is empty.\n",
        "    \"\"\"\n",
        "    x = str(x).strip()\n",
        "    \n",
        "    if x == \"\":\n",
        "        return None\n",
        "    else:\n",
        "        return x\n",
        "    \n",
        "def convert_df_to_dict(df: pd.DataFrame) -> Dict[str, Dict]:\n",
        "    \"\"\" Convert pandas DataFrame to dict keyed by record id.\n",
        "        Convert all fields to strings or Nones to satisfy dedupe.\n",
        "        Transform date format of date_of_birth field.\n",
        "    \"\"\"    \n",
        "\n",
        "    for col in df.columns:\n",
        "        df[col] = df[col].apply(lambda x: strip_and_null(x))\n",
        "\n",
        "    df[\"date_of_birth\"] = df[\"date_of_birth\"].apply(lambda x: format_dob(x))    \n",
        "\n",
        "    return df.to_dict(\"index\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHKmbbpEXygH"
      },
      "source": [
        "records_A = convert_df_to_dict(df_A)\n",
        "records_B = convert_df_to_dict(df_B)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eo3qlSBXygH"
      },
      "source": [
        "We can examine a small sample of the resulting transformed records:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRXrZzSRXygH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2475614-06da-49c2-8cd0-ad00a7696c73"
      },
      "source": [
        "[records_A[k] for k in list(records_A.keys())[0:2]]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'address_1': 'ballard place',\n",
              "  'address_2': 'None',\n",
              "  'age': '32',\n",
              "  'date_of_birth': None,\n",
              "  'first_name': 'matilda',\n",
              "  'phone_number': '03 05903135',\n",
              "  'postcode': '2470',\n",
              "  'soc_sec_id': '8276847',\n",
              "  'state': 'qld',\n",
              "  'street_number': '8',\n",
              "  'suburb': 'west perth',\n",
              "  'surname': 'struck'},\n",
              " {'address_1': 'kambalda crescent',\n",
              "  'address_2': 'villa 427',\n",
              "  'age': '27',\n",
              "  'date_of_birth': None,\n",
              "  'first_name': 'lachlan',\n",
              "  'phone_number': 'None',\n",
              "  'postcode': '5109',\n",
              "  'soc_sec_id': '9937958',\n",
              "  'state': 'None',\n",
              "  'street_number': '36',\n",
              "  'suburb': 'auburn',\n",
              "  'surname': 'eglinton'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37XGwdesXygI"
      },
      "source": [
        "# 6.0 Prepare Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O7a4XTTXygI"
      },
      "source": [
        "When we linked our data via SimSum and supervised learning, we defined our blockers and comparators manually with `recordlinkage`. The `dedupe` library takes an active learning approach to blocking and classification and will use our feedback gathered during the labeling session to learn blocking rules and train a classifier. \n",
        "\n",
        "To prepare our `dedupe.RecordLink` object for training, first we'll define the fields that we think `dedupe` should pay attention to when matching records - these definitions will serve as the comparators. The `field` contains the name of the attribute to use for comparison, and the `type` defines the comparison type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3srfBEUXygI"
      },
      "source": [
        "%%time\n",
        "\n",
        "fields = [\n",
        "    { \"field\" : \"first_name\", \"type\" : \"Name\" },\n",
        "    { \"field\" : \"surname\", \"type\" : \"Name\" },\n",
        "    { \"field\" : \"address_1\", \"type\" : \"ShortString\" },\n",
        "    { \"field\" : \"address_2\", \"type\" : \"ShortString\" },\n",
        "    { \"field\" : \"suburb\", \"type\" : \"ShortString\" },\n",
        "    { \"field\" : \"postcode\", \"type\" : \"Exact\" },\n",
        "    { \"field\" : \"state\", \"type\" : \"Exact\" },\n",
        "    { \"field\" : \"date_of_birth\", \"type\" : \"DateTime\" },\n",
        "    { \"field\" : \"soc_sec_id\", \"type\" : \"Exact\" },\n",
        "]\n",
        "\n",
        "linker = dedupe.RecordLink(fields)\n",
        "linker.prepare_training(records_A, records_B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECQ6XchIXygJ"
      },
      "source": [
        "#7.0 Do active learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxnYQuyqXygJ"
      },
      "source": [
        "At this point, we're ready to provide feedback to `dedupe` via an active learning labeling session. For this, `dedupe` supplies a convenience method to iterate through pairs it is uncertain about. As you provide feedback for each pair, dedupe learns blocking rules and recalculates its linking model weights.\n",
        "\n",
        "You can use `y` (yes, match), `n` (no, not match), and `u` (unsure) to provide feedback on candidate links. When you're ready to exit the labeling session, use `f`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPwv6n9ZXygJ"
      },
      "source": [
        "dedupe.console_label(linker)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AkW1kV9XygJ"
      },
      "source": [
        "We can now train our linker, based on the labeling session feedback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SItI6tntXygJ"
      },
      "source": [
        "%%time\n",
        "linker.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tub2ng5dXygJ"
      },
      "source": [
        "Let's persist our training data (captured during in the labeling session), as well as the learned model weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_WCfZSrXygK"
      },
      "source": [
        "ACTIVE_LEARNING_DIR = WORKING_DIR / \"dedupe_active_learning\"\n",
        "ACTIVE_LEARNING_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "SETTINGS_FILE = ACTIVE_LEARNING_DIR / \"dedupe_learned_settings\"\n",
        "TRAINING_FILE = ACTIVE_LEARNING_DIR / \"dedupe_training.json\"\n",
        "\n",
        "with open(TRAINING_FILE, \"w\") as fh:\n",
        "    linker.write_training(fh)\n",
        "    \n",
        "with open(SETTINGS_FILE, \"wb\") as sf:\n",
        "    linker.write_settings(sf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WskJQZ1XygK"
      },
      "source": [
        "## Examine Learned Blockers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i2n8-5TXygK"
      },
      "source": [
        "Now, let's take a look at the predicates (blockers) that `dedupe` learned during our active learning labeling session. Note that `dedupe` can learn composite predicates/blockers, i.e. individual predicates can be combined with logical operators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLJvsPqhXygK"
      },
      "source": [
        "linker.predicates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1C0iNi4XygK"
      },
      "source": [
        "Next, let's examine the resulting candidate pairs and look at our blocking efficiency. The `.pairs` method will give us all candidate record pairs that are generated by blocking with the learned blockers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNMgiivKXygK"
      },
      "source": [
        "candidate_pairs = [x for x in linker.pairs(records_A, records_B)]\n",
        "print(f\"{len(candidate_pairs):,} candidate pairs generated from blocking.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52K9bn_8XygK"
      },
      "source": [
        "You'll notice that, in contrast to `recordlinkage`, our post-blocking candidate pairs contain both the record ids as well as the record metadata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIELXfehXygL"
      },
      "source": [
        "candidate_pairs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTEV8vkhXygL"
      },
      "source": [
        "We can assemble our candidate pair ids into an indexed pandas dataframe for easier comparision with our known true links."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mg70HK0XygL"
      },
      "source": [
        "df_candidate_links = pd.DataFrame(\n",
        "    [(x[0][0], x[1][0]) for x in candidate_pairs]\n",
        ").rename(columns={0 : \"person_id_A\", 1 : \"person_id_B\"}).set_index([\"person_id_A\", \"person_id_B\"])\n",
        "\n",
        "df_candidate_links.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip00kypUXygL"
      },
      "source": [
        "Now, let's take a look at our learned blocker performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1SHlIFrXygL"
      },
      "source": [
        "max_candidate_pairs = df_A.shape[0]*df_B.shape[0]\n",
        "\n",
        "print(f\"{max_candidate_pairs:,} total possible pairs.\")\n",
        "\n",
        "# Calculate search space reduction.\n",
        "search_space_reduction = round(1 - len(candidate_pairs)/max_candidate_pairs, 6)\n",
        "print(f\"\\n{len(candidate_pairs):,} pairs after full blocking: {search_space_reduction}% search space reduction.\")\n",
        "\n",
        "# Calculate retained true links percentage.\n",
        "total_true_links = df_ground_truth.shape[0]\n",
        "true_links_after_blocking = pd.merge(\n",
        "    df_ground_truth,\n",
        "    df_candidate_links,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    how=\"inner\"\n",
        ").shape[0]\n",
        "\n",
        "retained_true_link_percent = round((true_links_after_blocking/total_true_links) * 100, 2)\n",
        "print(f\"{retained_true_link_percent}% true links retained after blocking.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrAwLzHqXygL"
      },
      "source": [
        "## Score Pairs and Examine Learned Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgsjs1oOXygM"
      },
      "source": [
        "After `dedupe` has trained blockers and a classification model based on our labeling session, we can link the records in our training dataset via the `.join` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebxIHSFoXygM"
      },
      "source": [
        "%%time\n",
        "linked_records = linker.join(records_A, records_B, threshold=0.0, constraint=\"one-to-one\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtWUzmwkXygM"
      },
      "source": [
        "`linker.join` will return the links, along with a model confidence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cag3cxivXygM"
      },
      "source": [
        "linked_records[0:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqbOp_H8XygM"
      },
      "source": [
        "We'll format the `dedupe` linker predictions into a format that we can use with our existing evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar0X3et6XygM"
      },
      "source": [
        "df_predictions = pd.DataFrame(\n",
        "    [ {\"person_id_A\" : x[0][0], \"person_id_B\" : x[0][1], \"model_score\" : x[1]} for x in linked_records]\n",
        ")\n",
        "\n",
        "df_predictions = df_predictions.set_index([\"person_id_A\", \"person_id_B\"])\n",
        "\n",
        "df_predictions = pd.merge(\n",
        "    df_predictions,\n",
        "    df_ground_truth,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "df_predictions[\"ground_truth\"].fillna(False, inplace=True)\n",
        "df_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oBUU9SzXygM"
      },
      "source": [
        "## Choosing a Linking Model Score Threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3igpyzfQXygM"
      },
      "source": [
        "The `dedupe` `.join` method that we used to score our training data directly incorporates the learned blockers. Thus, note that the scored pairs appearing on the distribution represent blocked pairs, and that our blockers *significantly* reduced the candidate pair search space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEz0-ZamXygQ"
      },
      "source": [
        "### Model Score Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuyBsNxwXygQ"
      },
      "source": [
        "df_predictions[\"ground_truth\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs20eIrfXygR"
      },
      "source": [
        "tutorial.plot_model_score_distribution(df_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dLKvFrdXygR"
      },
      "source": [
        "### Precision and Recall vs. Model Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcMkPVDZXygR"
      },
      "source": [
        "df_eval = tutorial.evaluate_linking(\n",
        "    df=df_predictions\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGXvwHw2XygR"
      },
      "source": [
        "df_eval.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM17y0t4XygR"
      },
      "source": [
        "tutorial.plot_precision_recall_vs_threshold(df_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD1vkNkpXygR"
      },
      "source": [
        "## Iterating with Active Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8oqrMh3XygS"
      },
      "source": [
        "When using active learning, we iterate on our linking solution, and incorporate progressively more labeled training data. Perhaps we're not satisfied with the current performance of the blockers or classifier, and we'd like to create more labeled examples for dedupe to train on.\n",
        "\n",
        "Recall that earlier, we saved off our existing training data from the first labeling session. We can load this persisted data into a `dedupe` linker, and kick off another labeling session. Perhaps, after investigating the data during our first cycle, we don't think that dedupe should include `address_1` and `address2` in its comparators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbp88TDzXygS"
      },
      "source": [
        "### Tweak the Linker and Use Existing Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJVIkXeOXygS"
      },
      "source": [
        "%%time\n",
        "\n",
        "fields = [\n",
        "    { \"field\" : \"first_name\", \"type\" : \"Name\" },\n",
        "    { \"field\" : \"surname\", \"type\" : \"Name\" },\n",
        "    { \"field\" : \"suburb\", \"type\" : \"ShortString\" },\n",
        "    { \"field\" : \"postcode\", \"type\" : \"Exact\" },\n",
        "    { \"field\" : \"state\", \"type\" : \"Exact\" },\n",
        "    { \"field\" : \"date_of_birth\", \"type\" : \"DateTime\" },\n",
        "    { \"field\" : \"soc_sec_id\", \"type\" : \"Exact\" },\n",
        "]\n",
        "\n",
        "linker2 = dedupe.RecordLink(fields)\n",
        "\n",
        "with open(TRAINING_FILE, \"r\") as fh:\n",
        "    linker2.prepare_training(records_A, records_B, training_file=fh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_F4-APMXygS"
      },
      "source": [
        "Now, we can kick off a second active learning/labeling session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKENWI5VXygS"
      },
      "source": [
        "dedupe.console_label(linker2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6cOQ5RpXygS"
      },
      "source": [
        "### Retrain the Linker and Examine Blocking Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdpSPOyGXygS"
      },
      "source": [
        "Now, let's retrain, and examine blocker performance. Ideally, we see an improved true link retention following our second labeling session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOGXIUD2XygT"
      },
      "source": [
        "%%time\n",
        "linker2.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiRuYSZQXygT"
      },
      "source": [
        "candidate_pairs = [x for x in linker2.pairs(records_A, records_B)]\n",
        "print(f\"{len(candidate_pairs):,} candidate pairs generated from blocking.\")\n",
        "\n",
        "df_candidate_links = pd.DataFrame(\n",
        "    [(x[0][0], x[1][0]) for x in candidate_pairs]\n",
        ").rename(columns={0 : \"person_id_A\", 1 : \"person_id_B\"}).set_index([\"person_id_A\", \"person_id_B\"])\n",
        "\n",
        "max_candidate_pairs = df_A.shape[0]*df_B.shape[0]\n",
        "\n",
        "print(f\"{max_candidate_pairs:,} total possible pairs.\")\n",
        "\n",
        "# Calculate search space reduction.\n",
        "search_space_reduction = round(1 - len(candidate_pairs)/max_candidate_pairs, 6)\n",
        "print(f\"\\n{len(candidate_pairs):,} pairs after full blocking: {search_space_reduction}% search space reduction.\")\n",
        "\n",
        "# Calculate retained true links percentage.\n",
        "total_true_links = df_ground_truth.shape[0]\n",
        "true_links_after_blocking = pd.merge(\n",
        "    df_ground_truth,\n",
        "    df_candidate_links,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    how=\"inner\"\n",
        ").shape[0]\n",
        "\n",
        "retained_true_link_percent = round((true_links_after_blocking/total_true_links) * 100, 2)\n",
        "print(f\"{retained_true_link_percent}% true links retained after blocking.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xessURV5XygT"
      },
      "source": [
        "### Evaluate Classification Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElcEPfmGXygT"
      },
      "source": [
        "%%time\n",
        "linked_records = linker2.join(records_A, records_B, threshold=0.0, constraint=\"one-to-one\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpfu3BzgXygT"
      },
      "source": [
        "df_predictions = pd.DataFrame(\n",
        "    [ {\"person_id_A\" : x[0][0], \"person_id_B\" : x[0][1], \"model_score\" : x[1]} for x in linked_records]\n",
        ")\n",
        "\n",
        "df_predictions = df_predictions.set_index([\"person_id_A\", \"person_id_B\"])\n",
        "\n",
        "df_predictions = pd.merge(\n",
        "    df_predictions,\n",
        "    df_ground_truth,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    how=\"left\",\n",
        ")\n",
        "\n",
        "df_predictions[\"ground_truth\"].fillna(False, inplace=True)\n",
        "df_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwaYCrFWXygT"
      },
      "source": [
        "df_predictions[\"ground_truth\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi0ksTo-XygU"
      },
      "source": [
        "tutorial.plot_model_score_distribution(df_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdCJEK1xXygU"
      },
      "source": [
        "df_eval = tutorial.evaluate_linking(\n",
        "    df=df_predictions\n",
        ")\n",
        "\n",
        "tutorial.plot_precision_recall_vs_threshold(df_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_5_UQNOXygU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}